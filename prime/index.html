<!doctype html>
<html lang="en">
  <head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-173182823-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        
        gtag('config', 'UA-173182823-1');
    </script>

    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <title>PRIME: Prediction with Model-based Planning</title>
    <meta name="author" content="Haoran Song">
    <meta name="description" content="Project page of Learning to Predict Vehicle Trajectories with Model-based Planning">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="icon" type="image/png" href="trajs.png">
    <!-- Format -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="../format/app.css">
    <link rel="stylesheet" href="../format/bootstrap.min.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    <script src="../format/app.js"></script>
    <!-- MathJax: A JavaScript display engine for mathematics that works in all browsers. -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <!-- Make all the links contained on this page to be opened with a new page. -->
    <base target="_blank" />
  </head>

  <body>
    <div class="container" id="main">
        <div class="row">
            <h1 class="col-md-12 text-center">
                Learning to Predict Vehicle Trajectories with<br />
                Model-based Planning<br />
                <small>
                    In Submission
                </small>
            </h1>
        </div>
        
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="http://song-haoran.com/">
                            Haoran Song
                        </a>
                    </li>
                    <li>
                        <a href="">
                            Di Luan
                        </a>
                    </li>
                    <li>
                        <a href="https://wenchaoding.github.io/">
                            Wenchao Ding
                        </a>
                    </li>
                    <li>
                        <a href="https://seng.ust.hk/about/people/faculty/michael-yu-wang/">
                            Michael Yu Wang
                        </a>
                    </li>
                    <li>
                        <a href="https://cqf.io/">
                           Qifeng Chen
                        </a>
                    </li>
                </ul>
            </div>
        </div>

        <div class="row">
            <div class="col-md-12 text-center">
                Hong Kong University of Science and Technology
            </div>
        </div>

        <!-- ##### Elements #####-->
        <div class="row">
                <div class="col-md-8 col-md-offset-2 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
                            <a href="PRIME_pre.pdf">
                            <img src="PRIME_cover.png" height="120px"><br>
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li>
                        <!-- <li>
                            <a href="https://youtu.be/eN4BBVUJ2NQ">
                            <img src="../images/youtube_icon.png" height="120px"><br>
                                <h4><strong>Talk</strong></h4>
                            </a>
                        </li> -->
                        <li>
                            <a href="https://github.com/Haoran-SONG/">
                            <img src="../images/github_icon.png" height="120px"><br>
                                <h4><strong>Code (Not ready)</strong></h4>
                            </a>
                        </li>
                    </ul>
                </div>
        </div>


        <!-- <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Example Results
                </h3>
                <video id="v0" width="100%" autoplay loop muted controls>
                  <source src="lighthouse_results.mp4" type="video/mp4" />
                </video>
            </div>
        </div> -->

        <!-- ##### Abstract #####-->
        <hr>
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
                    Predicting the future trajectories of on-road vehicles is critical for autonomous driving. 
                    In this paper, we introduce a novel prediction framework called PRIME, which stands for Prediction with Model-based Planning. 
                    Unlike recent prediction works that utilize neural networks to model scene context and produce unconstrained trajectories, 
                    PRIME is designed to generate accurate and feasibility-guaranteed future trajectory predictions, 
                    which guarantees the trajectory feasibility by exploiting a model-based generator to produce future trajectories under explicit constraints and enables accurate multimodal prediction by using a learning-based evaluator to select future trajectories. 
                    We conduct experiments on the large-scale Argoverse Motion Forecasting Benchmark. Our PRIME outperforms state-of-the-art methods in <b>prediction accuracy</b>, <b>feasibility</b>, and <b>robustness under imperfect tracking</b>. 
                    Furthermore, we achieve the <b>1st place</b> on the
                    <a href="https://eval.ai/web/challenges/challenge-page/454/leaderboard/1279#leaderboardrank-1">Argoverse Motion Forecasting Leaderboard</a>.

                </p>
            </div>
        </div>

        
        <!-- ##### Overview video #####-->
        <!-- <div class="row">
          <div class="col-md-8 col-md-offset-2">
              <h3>
                  Technical Video
              </h3>
              <div class="text-center">
                  <div style="position:relative;padding-top:56.25%;">
                      <iframe src="https://www.youtube.com/embed/eN4BBVUJ2NQ" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
                  </div>
              </div>
          </div>
        </div> -->

        <!-- ##### Motivation & Key idea #####-->
        <hr>
        <div class="row">
          <div class="col-md-8 col-md-offset-2">
              <h3>
                Motivation & Key idea
              </h3>
              <p class="text-justify">
                In traffic scenarios, most vehicles operate under their inherent kinematic constraints (e.g., non-holonomic motion constraints for vehicles) 
                while in compliance with the road structure (e.g., lane connectivity, static obstacles) 
                and semantic information (e.g., traffic lights, speed limits).
                <i>All these kinematic and environmental constraints explicitly regularize the trajectory space.</i> 
                <br />
                However, most existing future prediction approaches model traffic agents as points and produce sequences of future positions without constraints. 
                Such constraint-free predictions may be incompliant with kinematic or environmental characteristics, 
                which gives rise to massive uncertainty in the predicted future states. 
                Consequently, the downstream planning module would inevitably <i>undergo some extra burdens and even the "freezing robot problem."</i>
                <br />
                Moreover, the recent learning-based prediction models follow the typical paradigm of generating trajectory predictions by network regression that highly relies on long-term tracking results.
                But for some dense driving scenarios where the target would be momently occluded or suddenly appears within the sensing range, tracking results are discontinuous or not accumulated enough. 
                <i>The prediction accuracy would degrade under such imperfect tracking cases.</i>  
              </p>
              <img src="system.png" class="img-responsive" alt="Illustration of the PRIME system design">
              <br />
              <p class="text-justify">                 
                Toward overcoming these challenges, we propose a novel prediction architecture called PRIME.
                The critical idea is to exploit a model-based motion planner as the <b>prediction generator</b> to sample feasible future trajectories under explicit constraints, 
                together with a deep neural network as the <b>prediction evaluator</b> to model implicit interactions and select future trajectories by scoring.
                The novel architecture contributes to accurate, feasible, and robust trajectory predictions.
                <br>
                More specifically, 
                the model-based generator (left) which samples the target's feasible future trajectories \(\mathcal{T}\) 
                by taking its real-time state \(\mathbf{s}_{tar}^0\) and the map \(\mathcal{M}\), 
                while explicitly imposing kinematical and environmental constraints to guarantee trajectory feasibility; 
                the learning-based evaluator (right) which receives the feasible trajectories \(\mathcal{T}\) and all observed tracks \(\mathcal{S}\) 
                to model the implicit interactions among all traffic agents, and selects a final set of feasible trajectories \(\mathcal{T}_{tar}\subset\mathcal{T}\) as the prediction result.
              </p>
          </div>
        </div>

        <!-- ##### Framework Overview #####-->
        <hr>
        <div class="row">
          <div class="col-md-8 col-md-offset-2">
              <h3>
                  Framework Overview
              </h3>
              <img src="framework.png" class="img-responsive" alt="PRIME framework overview"><br>
              <p class="text-justify">
                The model-based generator searches reachable paths \(\mathcal{P}\) through the map with Depth-First-Search 
                and samples a set of feasible future trajectories \(\mathcal{T}\) with the Frenet Planer. 
                This part is detailed in our paper.
                <br>
                The learning-based evaluator first encodes scene context given by \((\mathcal{P}, \mathcal{T}, \mathcal{S})\), 
                including \(l\) paths in \(\mathcal{P}\), \((m+1)\) history tracks in \(\mathcal{S}\) and \(n\) future trajectories in \(\mathcal{T}\).
                
                The implicit agent-map interactions are learned in the subsequent attention modules: 
                P2T and P2F propagate the spatial information of each reference path \(\mathcal{P}_i\) into history tracks and corresponding future trajectories, 
                and A2A takes track tensors from P2T to capture the multi-agent interactions.
                
                As the path-based Frenet coordinate is used in our dual spatial representation, P2T, P2F, and A2A operate for each path, 
                while F2F fuses all the future trajectories processed by P2F to obtain a global understanding for the reachable space. 
                
                Subsequently, each feasible trajectory \(\mathcal{T}_{i,j}\) could query its track tensor \(\mathbf{X}_i(\mathbf{s}_{tar})\) from P2T, 
                interaction tensor \(\mathbf{Y}_i(\mathbf{s}_{tar})\) from A2A and future tensor \(\mathbf{Z}(\mathcal{T}_{i,j})\) from F2F, 
                and it is scored by feeding the concatenation of these tensors to fully-connected layers. 
                Finally, the evaluator ranks all feasible future trajectories in \(\mathcal{T}\) by scoring and outputs a final set of \(K\) predicted trajectories.  
              </p>
          </div>
        </div>

        <!-- ##### Quantitative #####-->
        <hr>
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Quantitative Results
                </h3>
                <img src="quan_result.png" class="img-responsive" alt="Some quantitative results"><br>
            </div>
        </div>

        <!-- ##### Qualitative #####-->
        <hr>
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Qualitative Results
                </h3>
                <p class="text-justify">
                    Qualitative results under various scenarios on the Argoverse validation set. 
                    The model-based generator produces the set of future trajectories \(\mathcal{T}\) (<font style="color:blue;font-weight:bold">blue</font>) with feasibility guaranteed, 
                    which well regularize the target vehicle's future trajectory space.
                    The learning-based evaluator selects \(K\) trajectories from \(\mathcal{T}\) as multimodal prediction results (<font style="color:red;font-weight:bold">red</font>), 
                    and the depth of red indicates their probability.
                </p>
                <div class="row">
                    <div class="columns is-multiline is-centered">
                      <table style="border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tr>
                          <td style="padding:0 5px 0 5px; "> <img src="example/3810_text.png" height="350" width="350" > </td>
                          <td style="padding:0 5px 0 5px;"> <img src="example/3819.png" height="350" width="350" ><br> </td>
                        </tr>
                        <tr>
                            <td style="padding:0 5px 0 5px; "> <img src="example/38151.png" height="350" width="350" > </td>
                            <td style="padding:0 5px 0 5px;"> <img src="example/2092.png" height="350" width="350" ><br> </td>
                        </tr>
                        <tr>
                            <td style="padding:0 5px 0 5px; "> <img src="example/13626.png" height="350" width="350" > </td>
                            <td style="padding:0 5px 0 5px;"> <img src="example/4032.png" height="350" width="350" ><br> </td>
                        </tr>
                        <tr>
                            <td style="padding:0 5px 0 5px; "> <img src="example/12570.png" height="350" width="350" > </td>
                            <td style="padding:0 5px 0 5px;"> <img src="example/2877.png" height="350" width="350" ><br> </td>
                        </tr>
                      </table>
                    </div>
                </div>
            </div>
        </div>


        <!-- ##### Comparison #####-->
        <hr>
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    More Comparisons
                </h3>
                <p class="text-justify">
                    Qualitative comparisons between ours (left) and LaneGCN (right) on the Argoverse validation set, with the same coloring scheme. 
                    Here, we use the current state-of-the-art method, LaneGCN, 
                    as a representative for typical prediction models that generate unconstrained trajectories by neural networks.
                    <br></br>
                    We show some common failures, including kinematically and environmentally infeasible predictions.
                    Due to kinematic constraints, vehicles cannot take a turn suddenly at high speed (1st row), or reverse their moving directions (2nd row). 
                    Also, the prediction results of turning with across lane boundaries (3rd row), or heading towards reverse lanes (4th row) are incompliant with environmental constraints.
                    Such infeasible predictions would cause redundant burdens for an AV to make decisions and motion plans.
                    By contrast, the future trajectory set (<font style="color:blue;font-weight:bold">blue</font>) produced by our model-based generator 
                    is explicitly regularized by kinematic and environmental constraints, and thereupon, makes accurate and reasonable future predictions (<font style="color:red;font-weight:bold">red</font>).
                </p>
                <div class="row">
                    <div class="columns is-multiline is-centered">
                      <table style="border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tr>
                          <td style="padding:0 5px 0 5px; "> <img src="compare/1908_11.png" height="350" width="350" > </td>
                          <td style="padding:0 5px 0 5px;"> <img src="compare/1908_22.png" height="350" width="350" ><br> </td>
                        </tr>
                        <tr>
                            <td style="padding:0 5px 0 5px; "> <img src="compare/29042_1.png" height="350" width="350" > </td>
                            <td style="padding:0 5px 0 5px;"> <img src="compare/29042_2.png" height="350" width="350" ><br> </td>
                        </tr>
                        <tr>
                            <td style="padding:0 5px 0 5px; "> <img src="compare/5155_1.png" height="350" width="350" > </td>
                            <td style="padding:0 5px 0 5px;"> <img src="compare/5155_2.png" height="350" width="350" ><br> </td>
                        </tr>
                        <tr>
                            <td style="padding:0 5px 0 5px; "> <img src="compare/3130_1.png" height="350" width="350" > </td>
                            <td style="padding:0 5px 0 5px;"> <img src="compare/3130_2.png" height="350" width="350" ><br> </td>
                        </tr>
                      </table>
                    </div>
                </div>
            </div>
        </div>
        
        <!-- ##### BibTex #####-->
        <hr>
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    BibTeX
                </h3>
                <div class="row align-items-center">
                    <div class="col py-3">
                        <pre class="border">
@article{song2021learning,
      title={Learning to Predict Vehicle Trajectories with Model-based Planning}, 
      author={Haoran Song and Di Luan and Wenchao Ding and Michael Yu Wang and Qifeng Chen},
      journal={arXiv preprint arXiv:2103.04027},
      year={2021}
}
</pre>
                    </div>
                </div>
            </div>
        </div>
    </div>
</body>
</html>